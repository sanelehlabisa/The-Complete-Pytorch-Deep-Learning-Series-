{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader as dataloader\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from Trainer import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size of our mini batches\n",
    "batch_size = 64\n",
    "\n",
    "# How many itterations of our dataset\n",
    "num_epochs = 10\n",
    "\n",
    "# Optimizer learning rate\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Initialise what epoch we start from\n",
    "start_epoch = 0\n",
    "\n",
    "# Initialise best valid accuracy \n",
    "best_valid_acc = 0\n",
    "\n",
    "# Where to load/save the dataset from \n",
    "data_set_root = \"../datasets\"\n",
    "\n",
    "# What to resize our images to \n",
    "image_size = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_from_checkpoint = False\n",
    "\n",
    "save_dir = '../data/Models'\n",
    "model_name = 'ResNet18_STL10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set device to GPU_indx if GPU is avaliable\n",
    "GPU_indx = 0\n",
    "device = torch.device(GPU_indx if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare a composition of transforms\n",
    "# A ll models from the Pytorch model Zoo where trained using images normalised with \n",
    "# the mean and std (one per channel) of the whole ImageNet Dataset\n",
    "# therefore the pretrained feature \"detectors\" of the model will expect the input to \n",
    "# be normalized in the same way \n",
    "# https://pytorch.org/docs/stable/torchvision/models.html\n",
    "transform = transforms.Compose([transforms.Resize(image_size),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                     std=[0.229, 0.224, 0.225])]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our STL10 Datasets\n",
    "# https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.STL10\n",
    "\n",
    "# Dataset definition is a bit different to MNIST and CIFAR10\n",
    "# STL10 has 3 different datasets, test, train and unlabeled\n",
    "# http://ai.stanford.edu/~acoates/stl10/\n",
    "# training set only has 5000 images and test set only 8000\n",
    "# Image size in this dataset are 96x96, larger then what we've been using\n",
    "\n",
    "train_data = datasets.STL10(data_set_root, split='train', download=True, transform=transform)\n",
    "test_data = datasets.STL10(data_set_root, split='test', download=True, transform=transform)\n",
    "\n",
    "# Split training data into train and validation set with 90/10% training/validation split\n",
    "validation_split = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data)*validation_split)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "train_data, valid_data = torch.utils.data.random_split(train_data, [n_train_examples, n_valid_examples],\n",
    "                                                       generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ResNet18 from the pytorch \"models\" module\n",
    "# This is reasonably sized model at 18 layers deep\n",
    "# ResNet Paper https://arxiv.org/pdf/1512.03385.pdf\n",
    "\n",
    "# https://pytorch.org/docs/stable/torchvision/models.html#torchvision.models.resnet18\n",
    "# If you are using an older version of Pytorch (0.12 or older)\n",
    "res_net = models.resnet18(pretrained=False).to(device)\n",
    "\n",
    "# This method is deprecated in newer versions of Pytorch.\n",
    "\n",
    "# If you are using a newer version of Pytorch (0.13+) you can use this method instead:\n",
    "# res_net = models.resnet18(weights=\"IMAGENET1K_V1\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Uncomment this when ready\n",
    "# Loop through all the learnable parameter objects (from the layers)\n",
    "# for param in res_net.parameters():\n",
    "# # Set to True to unfreeze layers\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the model, by swapping out the last fc layer for a different one\n",
    "# get the number of in_features into the last fc layer\n",
    "num_ftrs = res_net.fc.in_features\n",
    "\n",
    "# Redefine the last fc layer with a linear layer with 10 ouputs, \n",
    "# this layer's weights will be randomly initialised\n",
    "res_net.fc = nn.Linear(num_ftrs, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = ModelTrainer(model=res_net, device=device, loss_fun=nn.CrossEntropyLoss(), \n",
    "                             batch_size=batch_size, learning_rate=learning_rate, \n",
    "                             save_dir=save_dir, model_name=model_name, \n",
    "                             start_from_checkpoint=start_from_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.set_data(train_set=train_data, test_set=test_data, val_set=valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "images, labels = next(iter(model_trainer.test_loader))\n",
    "out = torchvision.utils.make_grid(images[0:8], normalize=True)\n",
    "_ = plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see how many Parameter's our Model has!\n",
    "num_params = 0\n",
    "for param in model_trainer.model.parameters():\n",
    "    num_params += param.flatten().shape[0]\n",
    "print(\"This model has %d (approximately %d Million) Parameters!\" % (num_params, num_params//1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell implements our training loop\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "valid_acc = 0\n",
    "train_acc = 0\n",
    "\n",
    "pbar = trange(start_epoch, num_epochs, leave=False, desc=\"Epoch\")    \n",
    "for epoch in pbar:\n",
    "    pbar.set_postfix_str('Accuracy: Train %.2f%%, Val %.2f%%' % (train_acc * 100, valid_acc * 100))\n",
    "    \n",
    "    # Call the training function and pass training dataloader etc\n",
    "    model_trainer.train_model()\n",
    "    \n",
    "    # Call the modules evaluate function for train and validation set\n",
    "    train_acc = model_trainer.evaluate_model(train_test_val=\"train\")\n",
    "    valid_acc = model_trainer.evaluate_model(train_test_val=\"val\")\n",
    "    \n",
    "    # Check if the current validation accuracy is greater than the previous best\n",
    "    # If so, then save the model\n",
    "    if valid_acc > model_trainer.best_valid_acc:\n",
    "        model_trainer.save_checkpoint(epoch, valid_acc)\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The highest validation accuracy was %.2f%%\" %(model_trainer.best_valid_acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training time %.2f seconds\" %(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_ = plt.figure(figsize = (10,5))\n",
    "train_x = np.linspace(0, num_epochs, len(model_trainer.train_loss_logger))\n",
    "_ = plt.plot(train_x, model_trainer.train_loss_logger)\n",
    "_ = plt.title(\"Training Loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_ = plt.figure(figsize = (10,5))\n",
    "train_x = np.linspace(0, num_epochs, len(model_trainer.train_acc_logger))\n",
    "_ = plt.plot(train_x, model_trainer.train_acc_logger, c = \"y\")\n",
    "valid_x = np.linspace(0, num_epochs, len(model_trainer.val_acc_logger))\n",
    "_ = plt.plot(valid_x, model_trainer.val_acc_logger, c = \"k\")\n",
    "\n",
    "_ = plt.title(\"Accuracy\")\n",
    "_ = plt.legend([\"Training accuracy\", \"Validation accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the evaluate function and pass the evaluation/test dataloader etc\n",
    "test_acc = model_trainer.evaluate_model(train_test_val=\"test\")\n",
    "print(\"The Test Accuracy is: %.2f%%\" %(test_acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
