U-Net Image Segmentation (From Scratch!) - PyTorch Deep Learning Tutorial
Overview
This tutorial covers the U-Net architecture for image segmentation, focusing on its implementation in PyTorch.
Key Concepts
U-Net Architecture

U-Net is designed for biomedical image segmentation and consists of:
Contracting Path: Downsampling with convolutional layers.
Bottleneck: The deepest layer that connects downsampling and upsampling.
Expansive Path: Upsampling with skip connections from the contracting path to retain spatial information.
Loss Function

Commonly used loss functions for segmentation tasks include:
Binary Cross-Entropy Loss:

loss = nn.BCELoss()
Dice Loss (for better handling of class imbalance):

def dice_loss(pred, target, smooth=1e-6):
    intersection = (pred * target).sum()
    return 1 - (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)
Implementation Steps

Define the U-Net Model:


import torch
import torch.nn as nn

class UNet(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(UNet, self).__init__()
        self.encoder1 = self.conv_block(in_channels, 64)
        self.encoder2 = self.conv_block(64, 128)
        self.encoder3 = self.conv_block(128, 256)
        self.encoder4 = self.conv_block(256, 512)
        self.bottleneck = self.conv_block(512, 1024)
        self.decoder4 = self.upconv_block(1024, 512)
        self.decoder3 = self.upconv_block(512, 256)
        self.decoder2 = self.upconv_block(256, 128)
        self.decoder1 = self.upconv_block(128, out_channels)

    def conv_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.ReLU(inplace=True)
        )

    def upconv_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        enc1 = self.encoder1(x)
        enc2 = self.encoder2(enc1)
        enc3 = self.encoder3(enc2)
        enc4 = self.encoder4(enc3)
        bottleneck = self.bottleneck(enc4)
        dec4 = self.decoder4(bottleneck)
        dec3 = self.decoder3(dec4 + enc4)  # Skip connection
        dec2 = self.decoder2(dec3 + enc3)  # Skip connection
        return self.decoder1(dec2 + enc2)  # Skip connection
Training Loop:

model = UNet(in_channels=1, out_channels=1)  # Example for grayscale images
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

for epoch in range(num_epochs):
    for images, masks in dataloader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = dice_loss(outputs, masks)  # or use BCELoss
        loss.backward()
        optimizer.step()
Output Generation

After training, output segmentation maps can be generated by passing images through the model:

with torch.no_grad():
    test_output = model(test_images)
Common Challenges

Class Imbalance: Often arises in segmentation tasks; consider using weighted loss functions.
Overfitting: Use techniques like data augmentation and dropout to mitigate.
Conclusion
The tutorial provides a foundational understanding of U-Net architecture for image segmentation, emphasizing its structure, loss functions, and training process.