PyTorch Deep Learning Tutorial: Basics of Convolutions
Introduction to Convolutions

This video marks the beginning of Section 4, focusing on 2D convolutions and convolutional neural networks (CNNs).
Convolutions are used to extract features from images, enabling tasks like edge detection.
Understanding Convolution

A convolution operation involves a kernel (filter) that slides over an input image, multiplying its values by the corresponding values in the kernel and summing them to produce an output.
The output is often referred to as a feature map.
Sobel Edge Detector

The video demonstrates implementing a Sobel edge detector, which highlights edges in an image by calculating gradients in the X and Y directions.
The Sobel kernel is defined for both directions and is used to detect areas of high contrast.
Kernel and Feature Maps

The shape of the kernel is defined as (output_channels, input_channels, height, width).
For a multi-channel input (e.g., RGB), the kernel must also match the number of channels.
Manual Convolution Implementation

The video shows how to manually implement a convolution using defined kernels to extract features from an image.
Results from the X and Y kernels can be combined using the magnitude to create a complete edge-detected output.
Learnable Convolutional Layers

Instead of manually defining kernels, convolutional layers in neural networks can learn to optimize their parameters during training.
PyTorch allows the creation of learnable convolutional layers using torch.nn.Conv2d.
Advantages of Convolutions

Convolutions reduce the number of parameters compared to fully connected layers, making them more efficient for image data.
They enable translation invariance, meaning the model can recognize features regardless of their position in the image.
Training a Convolutional Kernel

The video demonstrates training a convolutional kernel to learn edge detection by minimizing the loss between the output and a target image.
The target is derived by subtracting a blurred version of the original image from itself, emphasizing high-frequency components (edges).
Example Code Snippet for Sobel Edge Detection

import torch
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image

# Load and preprocess image
image = Image.open('path_to_image.jpg').convert('RGB')
transform = transforms.Compose([transforms.Resize((512, 512)), transforms.ToTensor()])
input_image = transform(image).unsqueeze(0)  # Add batch dimension

# Define Sobel kernels
sobel_x = torch.tensor([[[-1, 0, 1],
                          [-2, 0, 2],
                          [-1, 0, 1]]], dtype=torch.float32)  # Shape: (1, 1, 3, 3)

sobel_y = torch.tensor([[[-1, -2, -1],
                          [0, 0, 0],
                          [1, 2, 1]]], dtype=torch.float32)  # Shape: (1, 1, 3, 3)

# Apply convolution
edges_x = F.conv2d(input_image, sobel_x, padding=1)
edges_y = F.conv2d(input_image, sobel_y, padding=1)

# Combine results
edges = torch.sqrt(edges_x ** 2 + edges_y ** 2)