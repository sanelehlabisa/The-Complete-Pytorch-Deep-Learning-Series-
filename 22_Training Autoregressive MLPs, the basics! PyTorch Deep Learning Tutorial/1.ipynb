{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# reading lime_image\n",
    "from lime import lime_image\n",
    "\n",
    "from skimage.segmentation import mark_boundaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility.\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0) \n",
    "\n",
    "device =\"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# loading the model\n",
    "resnet = resnet18(pretrained=True)\n",
    "resnet = resnet.eval().to(device)\n",
    "\n",
    "# reading imagenet classes\n",
    "idx2label, cls2label, cls2idx = [], {}, {}\n",
    "with open(os.path.join(\"../data\",\"imagenet_class_index.json\"), 'r') as read_file:\n",
    "    class_idx = json.load(read_file)\n",
    "    idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
    "    cls2label = {class_idx[str(k)][0]: class_idx[str(k)][1] for k in range(len(class_idx))}\n",
    "    cls2idx = {class_idx[str(k)][0]: k for k in range(len(class_idx))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# resize and take the center part of image to what our model expects\n",
    "def pil_to_torch(img):\n",
    "    transf = T.Compose([\n",
    "        T.Resize((256, 256)),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225]) \n",
    "    ])        \n",
    "    # unsqeeze converts single image to batch of 1\n",
    "    return transf(img).unsqueeze(0)\n",
    "\n",
    "def pil_transform(img): \n",
    "    transf = T.Compose([\n",
    "        T.Resize((256, 256)),\n",
    "        T.CenterCrop(224)\n",
    "    ])    \n",
    "\n",
    "    return transf(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def cnn_predict(images): \n",
    "    transf = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    batch = torch.stack(tuple(transf(img) for img in images), dim=0)\n",
    "\n",
    "    logits = resnet(batch.to(device)).cpu()\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    return probs.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img_file_name = \"puppy_kitten.jpg\"\n",
    "img_pil_0 = Image.open(os.path.join(\"../data\",img_file_name)).convert('RGB')\n",
    "\n",
    "_ = plt.imshow(img_pil_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img0 = pil_to_torch(img_pil_0)\n",
    "\n",
    "logits = resnet(img0.to(device))\n",
    "probs = F.softmax(logits, dim=1).cpu()\n",
    "probs5 = probs.topk(5)\n",
    "tuple((p,c, idx2label[c]) for p, c in zip(probs5[0][0].detach().numpy(), probs5[1][0].detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "explanation = explainer.explain_instance(np.array(pil_transform(img_pil_0)), \n",
    "                                         cnn_predict, # classification function\n",
    "                                         top_labels=2, \n",
    "                                         hide_color=0, \n",
    "                                         num_samples=1000) # number of images that will be sent to classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(20, 10))\n",
    "\n",
    "axes[0].imshow(pil_transform(img_pil_0))\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title(\"Original Image\")\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], \n",
    "                                            positive_only=True, negative_only=False, \n",
    "                                            num_features=5, hide_rest=True)\n",
    "\n",
    "img_boundry = mark_boundaries(temp/255.0, mask)\n",
    "axes[1].imshow(img_boundry)\n",
    "axes[1].set_title(\"Positive mask\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], \n",
    "                                            positive_only=False, negative_only=True, \n",
    "                                            num_features=5, hide_rest=True)\n",
    "\n",
    "img_boundry = mark_boundaries(temp/255.0, mask)\n",
    "axes[2].imshow(img_boundry)\n",
    "axes[2].set_title(\"Negative mask\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img_file_name = \"fruit.jpg\"\n",
    "img_pil_1 = Image.open(os.path.join(\"../data\",img_file_name)).convert('RGB')\n",
    "\n",
    "img1 = pil_to_torch(img_pil_1)\n",
    "logits = resnet(img1.to(device)).cpu()\n",
    "probs = F.softmax(logits, dim=1)\n",
    "probs5 = probs.topk(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "_ = plt.imshow(img_pil_1)\n",
    "labels = tuple((p,c, idx2label[c]) for p, c in zip(probs5[0][0].detach().numpy(), probs5[1][0].detach().numpy()))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "explanation = explainer.explain_instance(np.array(pil_transform(img_pil_1)), \n",
    "                                         cnn_predict, # classification function\n",
    "                                         top_labels=5, \n",
    "                                         hide_color=0, \n",
    "                                         num_samples=1000) # number of images that will be sent to classification function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "label = 3\n",
    "print(\"Looking at:\", labels[label][-1])\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(20, 10))\n",
    "axes[0].imshow(pil_transform(img_pil_1))\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title(\"Original Image\")\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[label], positive_only=True, \n",
    "                                            negative_only=False, num_features=3, hide_rest=True)\n",
    "img_boundry = mark_boundaries(temp/255.0, mask)\n",
    "axes[1].imshow(img_boundry)\n",
    "axes[1].set_title(\"Positive mask\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[label], positive_only=False, \n",
    "                                            negative_only=True, num_features=10, hide_rest=True)\n",
    "\n",
    "img_boundry = mark_boundaries(temp/255.0, mask)\n",
    "axes[2].imshow(img_boundry)\n",
    "axes[2].set_title(\"Negative mask\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
