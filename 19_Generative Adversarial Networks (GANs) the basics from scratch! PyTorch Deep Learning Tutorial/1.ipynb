{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative Adversarial Network in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "batch_size = 512\n",
    "dlr = 1e-4\n",
    "glr = 1e-4\n",
    "\n",
    "train_epoch = 100\n",
    "\n",
    "# data_loader\n",
    "img_size = 32\n",
    "\n",
    "data_set_root = \"../datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "gpu_indx  = 0\n",
    "device = torch.device(gpu_indx if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                                transforms.Resize(img_size),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=([0.5]), std=([0.5]))\n",
    "                                ])\n",
    "\n",
    "trainset = datasets.MNIST(data_set_root, train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z=64, ch=16):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv1 = nn.ConvTranspose2d(z, ch * 4, 4, 1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(ch * 4, ch * 4, 3, 1, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(ch * 4)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(ch * 4, ch * 2, 3, 1, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(ch * 2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(ch * 2, ch * 2, 3, 1, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(ch * 2)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(ch * 2, ch * 2, 3, 1, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(ch * 2)\n",
    "\n",
    "        self.conv_out = nn.Conv2d(ch * 2, 1, 3, 1, 1)\n",
    "        self.up_nn = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "\n",
    "    # Forward method\n",
    "    def forward(self, x):        \n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.up_nn(F.elu(self.bn1(self.conv2(x))))\n",
    "        x = self.up_nn(F.elu(self.bn2(self.conv3(x))))\n",
    "        x = self.up_nn(F.elu(self.bn3(self.conv4(x))))\n",
    "        x = F.elu(self.bn4(self.conv5(x)))\n",
    "\n",
    "        return torch.tanh(self.conv_out(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, ch=16):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv_in = nn.Conv2d(1, ch, 3, 1, 1)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(ch, ch*2, 3, 2, 1)        \n",
    "        self.conv2 = nn.Conv2d(ch*2, ch*2, 3, 2, 1)        \n",
    "        self.conv3 = nn.Conv2d(ch*2, ch*4, 3, 2, 1)        \n",
    "        self.conv4 = nn.Conv2d(ch*4, ch*4, 3, 2, 1)\n",
    "        self.bn = nn.BatchNorm2d(ch*4)\n",
    "        \n",
    "        self.do = nn.Dropout()\n",
    "        self.conv5 = nn.Conv2d(ch*4, 1, 2, 1)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.conv_in(x))\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.do(F.elu(self.bn(self.conv4(x))))\n",
    "        x = self.conv5(x).reshape(x.shape[0], 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_bce_loss(output, real_label=True):\n",
    "    if real_label:\n",
    "        return F.binary_cross_entropy_with_logits(output, torch.ones_like(output))\n",
    "    else:     \n",
    "        return F.binary_cross_entropy_with_logits(output, torch.zeros_like(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_w_loss(output, real_label=True):\n",
    "    if real_label:\n",
    "        return -output.mean()\n",
    "    else:     \n",
    "        return output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network\n",
    "latent_noise_dem = 128\n",
    "\n",
    "g_net = Generator(latent_noise_dem, ch=32).to(device)\n",
    "d_net = Discriminator(ch=32).to(device)\n",
    "\n",
    "#A fixed latent noise vector so we can see the improvement over the epochs\n",
    "fixed_latent_noise = torch.randn(16, latent_noise_dem, 1, 1).to(device)\n",
    "\n",
    "# Adam optimizer\n",
    "g_optimizer = optim.Adam(g_net.parameters(), lr=glr)\n",
    "d_optimizer = optim.Adam(d_net.parameters(), lr=dlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using gradient clipping, initialise the params to be smaller\n",
    "# with torch.no_grad():\n",
    "#     for param in d_net.parameters():\n",
    "#         param.data *= 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_images_log = []\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "d_out_fake = []\n",
    "d_out_real = []\n",
    "\n",
    "g_loss = 0\n",
    "d_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  18%|█▊        | 18/100 [74:39:09<124:07:11, 5449.16s/it, G Loss: 1.0659, D Loss: 0.5931]  "
     ]
    }
   ],
   "source": [
    "pbar = trange(train_epoch, leave=False, desc=\"Epoch\")    \n",
    "for epoch in pbar:\n",
    "    pbar.set_postfix_str('G Loss: %.4f, D Loss: %.4f' % (g_loss/len(train_loader), \n",
    "                                                         d_loss/len(train_loader)))\n",
    "    g_loss = 0\n",
    "    d_loss = 0\n",
    "\n",
    "    for num_iter, (images, label) in enumerate(tqdm(train_loader, leave=False)):\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for param in d_net.parameters():\n",
    "#                 param.clamp_(-0.05, 0.05)\n",
    "\n",
    "        images = images.to(device)\n",
    "        \n",
    "        #the size of the current minibatch\n",
    "        bs = images.shape[0]\n",
    "\n",
    "        ########### Train Generator G ##############\n",
    "        #Step1: Sample a latent vector from a normal distribution and pass it through the generator\n",
    "        #to get a batch of fake images\n",
    "        latent_noise = torch.randn(bs, latent_noise_dem, 1, 1).to(device)\n",
    "        g_output = g_net(latent_noise)\n",
    "        \n",
    "        #Step3: Pass the minibatch of fake images (from the Generator) through the Discriminator and calculate\n",
    "        #the loss against the \"real\" label - the Generator wants the discriminator to think it's outputs are real\n",
    "        d_result = d_net(g_output)\n",
    "        g_train_loss = gan_bce_loss(d_result, True)\n",
    "        \n",
    "        #Step4: Backpropogate the loss through the discriminator and into the Generator and take a training step \n",
    "        g_net.zero_grad()\n",
    "        g_train_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        #log the generator training loss\n",
    "        g_losses.append(g_train_loss.item())\n",
    "        g_loss += g_train_loss.item()\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for param in g_net.parameters():\n",
    "#                 param.clamp_(-0.01, 0.01)\n",
    "        \n",
    "        ########### Train Discriminator D! ############\n",
    "        \n",
    "        #Step1: Pass the minibatch of real images through the Discriminator and calculate\n",
    "        #the loss against the \"real\" label\n",
    "        d_real_out = d_net(images)\n",
    "        d_real_loss = gan_bce_loss(d_real_out, True)\n",
    "        d_out_real.append(d_real_out.mean().item())\n",
    "        \n",
    "        #Step2: Pass the minibatch of fake images (from the Generator) through the Discriminator and calculate\n",
    "        #the loss against the \"fake\" label\n",
    "        #We \"detach()\" the output of the Generator here as we don't need it to backpropagate through the\n",
    "        #Generator in this step\n",
    "        d_fake_out = d_net(g_output.detach())\n",
    "        d_fake_loss = gan_bce_loss(d_fake_out, False)\n",
    "        d_out_fake.append(d_fake_out.mean().item())\n",
    "\n",
    "        #Step3: Add the two losses together, backpropogate through the discriminator and take a training step \n",
    "        d_train_loss = (d_real_loss + d_fake_loss)/2\n",
    "\n",
    "        d_net.zero_grad()\n",
    "        d_train_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        #log the discriminator training loss\n",
    "        d_losses.append(d_train_loss.item())\n",
    "        d_loss += d_train_loss.item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        g_net.eval()\n",
    "        #log the output of the generator given the fixed latent noise vector\n",
    "        test_fake = g_net(fixed_latent_noise)\n",
    "        imgs = torchvision.utils.make_grid(test_fake.cpu().detach(), 4, pad_value=1, normalize=True)\n",
    "        imgs_np = (imgs.numpy().transpose((1, 2, 0)) * 255).astype(np.uint8)\n",
    "        test_images_log.append(imgs_np)\n",
    "        g_net.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fake = g_net(fixed_latent_noise)\n",
    "plt.figure(figsize = (20,10))\n",
    "out = vutils.make_grid(test_fake.detach().cpu(), 4, normalize=True)\n",
    "plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimsave('MNIST_GAN.gif', test_images_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
