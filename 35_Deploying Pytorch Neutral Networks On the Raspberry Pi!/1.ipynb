{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transform as defined for the pre-trained model\n",
    "# https://pytorch.org/blog/introducing-torchvision-new-multi-weight-support-api/\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(224),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                     std=[0.229, 0.224, 0.225])]) \n",
    "\n",
    "device = torch.device(0 if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained efficientnet_b1 model\n",
    "res_net = models.efficientnet_b1(weights=\"IMAGENET1K_V2\").to(device)\n",
    "\n",
    "# Set to eval mode for inference!\n",
    "res_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test image\n",
    "test_image = Image.open(\"../../data/dog.jpg\")\n",
    "test_image.resize((256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor\n",
    "tensor_image = transform(test_image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store inference times\n",
    "inference_time = []\n",
    "\n",
    "# Perform multiple inference runs (10 in this case)\n",
    "for _ in range(10):\n",
    "  # Record start time\n",
    "  start_time = time.time()\n",
    "\n",
    "  # Forward pass of model\n",
    "  out_put = res_net(tensor_image.to(device))\n",
    "\n",
    "  # Record end time\n",
    "  end_time = time.time()\n",
    "\n",
    "  # Calculate and store inference time for this run\n",
    "  inference_time.append(end_time - start_time)\n",
    "\n",
    "# Print the minimum inference time observed across the runs\n",
    "print(\"Minimum inference time %.4fs\" % np.min(inference_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random input tensor to be used for tracing (it does not need to be a \"real\" example!)\n",
    "test_input = torch.randn(1, 3, 224, 224, device=device)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(\n",
    "    res_net, # Model to convert\n",
    "    test_input, # Example input\n",
    "    \"efficientnet_b1.onnx\", # Output save name\n",
    "    opset_version=12, # Version of ONNX operations to use\n",
    "    export_params=True, # We will store the trained parameter weights inside the ONNX model file\n",
    "    do_constant_folding=True, # Whether to execute \"constant folding\" for optimization\n",
    "    input_names=['input'], # Define the model's input names\n",
    "    output_names=['output'], # Define the model's output names\n",
    "    dynamic_axes={'input' : {0 : 'batch_size'}, # Define any variable length axes\n",
    "                  'output' : {0 : 'batch_size'}}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
